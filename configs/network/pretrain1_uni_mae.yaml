
patch_size: 16
encoder_embed_dim: 768
encoder_heads: 12
encoder_depth: 3
trunk_depth: 9
mask_ratio: 0.4

encoder:
  _target_: t3.models.MAEViTEncoder
  mask_ratio: ${mask_ratio}
  patch_size: ${patch_size}
  embed_dim: ${encoder_embed_dim}
  depth: ${encoder_depth}
  num_heads: ${encoder_heads}
  mlp_ratio: 4. 

    
shared_trunk:
  _target_: t3.models.TransformerTrunk
  embed_dim: ${encoder_embed_dim}
  depth: ${trunk_depth}
  num_heads: ${encoder_heads}
  mlp_ratio: 4.

decoders:
  mae_recon_single:
    _target_: t3.models.MAEViTDecoder
    patch_size: ${patch_size}
    embed_dim: ${encoder_embed_dim}
    decoder_embed_dim: 512
    decoder_depth: 8
    decoder_num_heads: 16
    mlp_ratio: 4. 
    loss_func:
      _target_: t3.models.MAEReconLoss
      patch_size: 16
      norm_pix_loss: true # true for better representation learning, false for pixel-based loss for better reconstruction aka visualization